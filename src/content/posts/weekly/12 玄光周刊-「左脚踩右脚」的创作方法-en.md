---
title: 12 Black Light Weekly - The "Left Foot Stepping on Right Foot" Creative Method
published: 2026-02-03
description: What does "left foot stepping on right foot" mean? Let me explain it to you slowly...
updated: 2026-02-03
tags:
  - Weekly
draft: false
pin: 0
toc: true
lang: en
abbrlink: weekly-12
---

![cover](../_images/12%20ç„å…‰å‘¨åˆŠ-ã€Œå·¦è„šè¸©å³è„šã€çš„åˆ›ä½œæ–¹æ³•-1769845597946.webp)

This week's cover comes from my supervisorâ€”it doesn't love work but enjoys watching me work. Staring at the mouse cursor moving back and forth, it can persist here for 3 hours. It doesn't like hard wooden desktops, so I sacrificed my laptop sleeve. If replaced with a softer mat, it would probably persist even longer.

## The "Left Foot Stepping on Right Foot" Creative Method

Have you ever had this experience: organizing notes to write an article, but during the note organization process, new article ideas emerge? Like "left foot stepping on right foot" in martial arts novelsâ€”seemingly impossible but able to gain leverage in mid-air, achieving new ascension. Recently, while improving my knowledge base and writing, I frequently experienced this "self-propelling" cycle.

This might sound mystical, but the core lies in deeply coupling the two processes of **creative output** and **knowledge management**. It's not creating from nothing but actively applying and feeding back into your existing systemâ€”like the "thought specimen" library I mentioned in [Fragment Writing - Building a Thought Specimen](link), and the "style landscapes (Stylescapes)" discussed in [07 Xuan Guang Weekly - Double Diamond Design Model: Golden Framework Analysis from User Needs to Product Implementation](link).

Specifically, this cycle contains two interlocking "feet":

1. **Right Foot (Knowledge Management as Creation)**: Stop viewing note-taking as mere collection. Whenever reading, observing, or thinking, force yourself to record with "writing intention." Not copying but annotating, connecting, raising questions, forming individual "content embryos" with independent viewpoints. This is like building the "questioning framework" mentioned in [When AI Starts "Learning": How Should We Ask ChatGPT Questions?](obsidian://open?file=%E5%BD%93AI%E5%BC%80%E5%A7%8B%E2%80%9C%E5%AD%A6%E4%B9%A0%E2%80%9D%EF%BC%9A%E6%88%91%E4%BB%AC%E8%AF%A5%E5%A6%82%E4%BD%95%E5%90%91ChatGPT%E6%8F%90%E9%97%AE%EF%BC%9F.md), preparing structured ammunition for output.

2. **Left Foot (Creation as Knowledge Management)**: When needing formal writing (like this weekly), directly return to your note library for "treasure hunting." The writing process becomes a thematic "compilation," deep stitching, and logical sublimation of your fragmented notes. The completed article's core viewpoints and framework are then decomposed into new notes, re-sedimented into the knowledge base, waiting for next invocation and evolution.

This method breaks the linear "input - organize - output" process, making both parallel, mutually nourishing spirals. Its greatest benefit is **curing "blank page fear"**â€”you never start from zero; each creation iterates and realizes existing thinking. Of course, it requires your knowledge base itself to be "alive," filled with your own links and thinking, not an information graveyard. This also makes me reflect that perhaps the best creative tool is a system allowing convenient "left foot stepping on right foot."

Have you had similar "self-propelling" experiences? What are your "left foot" and "right foot" respectively? Welcome to share in comments below or via letter.

## Discovered Good Stuff

### Tencent Hunyuan Motion

![GitHub Introduction](../_images/12%20ç„å…‰å‘¨åˆŠ-ã€Œå·¦è„šè¸©å³è„šã€çš„åˆ›ä½œæ–¹æ³•-1769840627504.webp)

An open-source 3D motion generation large model launched by Tencent Hunyuan at year-end, currently mainly used for text-to-3D-character-motion direction. Most surprising is it's open-sourceâ€”meaning animators or small game development teams can use it to quickly build storyboards, prototypes, theoretically saving significant production costs.

![Hardware Requirements](../_images/12%20ç„å…‰å‘¨åˆŠ-ã€Œå·¦è„šè¸©å³è„šã€çš„åˆ›ä½œæ–¹æ³•-1769841119800.webp)

Of course, such models require higher hardware foundation compared to relatively simple Chat models. Motion effects demonstrated on the website introduction are quite goodâ€”should integrate well into existing workflows. Will try deploying one to test.

Link: <https://hunyuan.tencent.com/motion>

### Submitted a Bug to Centileo Renderer

Using version 0.717 with C4D 2025, graphics card 5070ti.

![This area wasn't denoised](../_images/12%20ç„å…‰å‘¨åˆŠ-ã€Œå·¦è„šè¸©å³è„šã€çš„åˆ›ä½œæ–¹æ³•-1769846783177.webp)

The phenomenon is shown aboveâ€”enabling denoising creates uneven blocks, more pronounced with higher parameters. Already reported to the developer, and they've started investigating the cause. Temporarily reverted to an older version, and the bug disappeared.

![Great atmosphere in the international 3D community](../_images/12%20ç„å…‰å‘¨åˆŠ-ã€Œå·¦è„šè¸©å³è„šã€çš„åˆ›ä½œæ–¹æ³•-1769847291817.webp)

Still strongly recommend Max and C4D users try this renderer ASAPâ€”it's incredibly fast compared to RS and OC, currently completely free. Previous introduction can be seen at ğŸ‘‰[04 Black Light Weekly - Refurbished Graphics Card and New Renderer | CGArtLab](https://cgartlab.com/posts/weekly-04/). I've been using it as my main renderer for over a year, definitely rendering thousands of hours. Of course, beta products inevitably have minor issuesâ€”looking forward to the official release.

### OpenClaw ğŸ¦

![The famous little lobster](../_images/12%20ç„å…‰å‘¨åˆŠ-ã€Œå·¦è„šè¸©å³è„šã€çš„åˆ›ä½œæ–¹æ³•-1770120784410.webp)

OpenClaw exploded in popularity this yearâ€”in my view, it has the potential to create truly meaningful AIPC.

Installed and heavily used for about a dayâ€”here are some impressions:

First, its freedom is somewhat frightening. Initially configured with Qwen-Maxâ€”a trick learned from other articles, supposedly less prone to crashing, and it really worked. But I wanted to switch to SiliconFlow's API because they have many invitation credits perfect for testing, so I sent the key saying "I heard you're amazing, configure yourself and notify me when done." Result: configured in about 2 minutes... WTF? And it chose the most cost-effective DeepSeek-V3.2!

**Definitely don't install on your main machine.**

Second, it really burns through tokens. To implant memory, I chatted with it for half an hour, had it crawl my articles, analyze my tools, writing style, etc... and burned over 3 million tokens. Luckily it was DeepSeek, costing about 10 RMB. If configured with GPT or Claude, definitely for the wealthy. After setting up long-term memory, I switched to Qwen3-8B small model for regular use, can switch back to large model with one command when needed.

Interestingly, I tried having DeepSeek lead Qwen's small model for division of laborâ€”might save many tokens. Unexpectedly, it actually devised a judgment strategy, then automatically switched to Qwen! This is somewhat terrifying to think about...

![More terrifying execution power than conversational AI](../_images/12%20ç„å…‰å‘¨åˆŠ-ã€Œå·¦è„šè¸©å³è„šã€çš„åˆ›ä½œæ–¹æ³•-1770122579659.webp)

Third, deployment and installation still have high barriers for newcomers. If you don't chase new tech, better wait and seeâ€”such hot things usually evolve quickly to out-of-the-box usability. Saw group messages saying people are already selling one-click installation Chinese versions on secondhand marketsâ€”haha, they deserve to make money!

Fourth, it's excellent for training other Agents. Links, text, various information thrown at it can form long-term memory, gradually understanding your style and habits better. Eventually these memories are stored in a text file, very compact. If this text is well-trained, throwing it to any conversational AI to remember could instantly create a personalized assistant. Still the "data portability" principleâ€”switching platforms shouldn't be a problem.

Fifth, this thing is way more fun than chat assistants. Just the first day, my usage is still very basicâ€”many skills not unlocked yet, like various skill functions, clawhub, scheduled tasks, etc... Enough for now.

Writing installation tutorials for such tools seems not very valuableâ€”changes too fast, won't write one. Better share unique usage methods after more experience.

If anyone wants to try, can register on SiliconFlow for free playâ€”covers most domestic models seen on the market. Using the link below, both you and I get extra 20 million tokens, enough for several days. Of course, you can use it for more cost-effective thingsâ€”20 million tokens can actually last a long time, it's just this little lobster burns through them quickly.

Link: <https://cloud.siliconflow.cn/i/09r0o1Ax>

### Casual Talk

I'm considering whether to merge the "Good Stuff" series into the weekly. Digital world good stuff and physical good stuff aren't conflictingâ€”both are things I discover and want to share. Publishing separately only superficially increases article count and update frequency; merging would substantially improve quality. Even if writing quality doesn't improve, at least might save others from opening another article and waiting another day. What do you think?

---

This article first published on [Black Light Weekly](https://weekly.cgartlab.com) simultaneously serialized on [CG Art Lab](https://cgartlab.com)

> About Black Light Weekly
>
> This is an electronic weekly focusing on knowledge management, covering digital art, visual design, and frontend development. Currently published weekly, each issue selects a specific topic for in-depth reflection. It shares my notes about entrepreneurship and products, including my thoughts, excerpts and annotations, reading notes, and quality content recommendations.
>
> If you find the content here worthwhile and want a better reading experience, more recommended to use browser to visit the official website. Also welcome to use **RSS** (<https://weekly.cgartlab.com/feed/atom>) or **Email Subscription** (<https://weekly.cgartlab.com>), we summarize these notes into an email sent to you weekly. Of course, your [letters](mailto:info@cgartlab.com) are also welcome.
